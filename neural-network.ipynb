{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baffa306-21e6-4f29-a4f9-83e58eeeffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np    #numpy is a package for scientific computing\n",
    "from collections import Counter\n",
    "vocab = Counter()\n",
    "text = \"Hi from Brazil\"\n",
    "#Get all words\n",
    "for word in text.split(' '):\n",
    "    vocab[word]+=1\n",
    "        \n",
    "#Convert words to indexes\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word] = i\n",
    "        \n",
    "    return word2index\n",
    "#Now we have an index\n",
    "word2index = get_word_2_index(vocab)\n",
    "total_words = len(vocab)\n",
    "#This is how we create a numpy array (our matrix)\n",
    "matrix = np.zeros((total_words),dtype=float)\n",
    "#Now we fill the values\n",
    "for word in text.split():\n",
    "    matrix[word2index[word]] += 1\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faffda87-21aa-4ff6-8ebe-07e7428225d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.zeros((total_words),dtype=float)\n",
    "text = \"Hi\"\n",
    "print(matrix)\n",
    "for word in text.split():\n",
    "    matrix[word2index[word]] += 1\n",
    "print(matrix)\n",
    "#for word in text.split():\n",
    "    #print(word)\n",
    "    #print(matrix)\n",
    "    #print(word2index[word])\n",
    "    #matrix[get_word_2_index[word]] += 1\n",
    "#print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccca97c9-77dc-4a4c-9755-1bc00309b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category=0;\n",
    "y = np.zeros((3),dtype=float)\n",
    "if category == 0:\n",
    "    y[0] = 1.        # [ 1.  0.  0.]\n",
    "elif category == 1:\n",
    "    y[1] = 1.        # [ 0.  1.  0.]\n",
    "else:\n",
    "     y[2] = 1.       # [ 0.  0.  1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96bc3532-45da-43ce-b0eb-cc6285cff9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = [\"comp.graphics\",\"sci.space\",\"rec.sport.baseball\"]\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75e877a-5261-4718-8b43-ab67d013068a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils._bunch.Bunch"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf389c0-c67d-4e7c-9132-41689f1e682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 15:43:06.455151: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c555c3-7c02-4510-99e1-d81065b019b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yuvisa/anaconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "n_input = total_words # Words in vocab\n",
    "n_classes = 3         # Categories: graphics, sci.space and baseball\n",
    "input_tensor = tf.placeholder(tf.float32,[None, n_input],name=\"input\")\n",
    "output_tensor = tf.placeholder(tf.float32,[None, n_classes],name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51582018-db43-438d-a4a6-829a7a12db5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)\n",
    "type(newsgroups_train.data)\n",
    "data(newsgroups_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ef9c774-98af-446f-9781-c0944c19ceed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Loop over all batches\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_batch):\n\u001b[0;32m---> 21\u001b[0m     batch_x,batch_y \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewsgroups_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Run optimization op (backprop) and cost op (to get loss value)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     c,_ \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun([loss,optimizer], feed_dict\u001b[38;5;241m=\u001b[39m{input_tensor: batch_x, output_tensor:batch_y})\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(data, batch_num, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m batch_num \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[1;32m      3\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m (batch_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m----> 4\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m \n\u001b[1;32m      5\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m labels[start_idx:end_idx]  \u001b[38;5;66;03m# Modify based on your data structure\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_x, batch_y\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "def get_batch(data, batch_num, batch_size):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = (batch_num + 1) * batch_size\n",
    "    batch_x = data[start_idx:end_idx] \n",
    "    batch_y = labels[start_idx:end_idx]  # Modify based on your data structure\n",
    "\n",
    "    return batch_x, batch_y\n",
    "\n",
    "batch_size=500;\n",
    "training_epochs = 10\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    init=tf.compat.v1.global_variables_initializer();\n",
    "    sess.run(init) #inits the variables (normal distribution, remember?)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(len(newsgroups_train.data)/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x,batch_y = get_batch(newsgroups_train,i,batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            c,_ = sess.run([loss,optimizer], feed_dict={input_tensor: batch_x, output_tensor:batch_y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
