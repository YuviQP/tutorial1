{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a78fb4-ee40-4f51-9bed-b3e9e982adec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/yuvisa/anaconda3/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: typing_extensions in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Collecting pytorch_pretrained_bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from pytorch_pretrained_bert) (1.12.1)\n",
      "Requirement already satisfied: numpy in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from pytorch_pretrained_bert) (1.22.3)\n",
      "Collecting boto3 (from pytorch_pretrained_bert)\n",
      "  Downloading boto3-1.28.70-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: requests in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from pytorch_pretrained_bert) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from pytorch_pretrained_bert) (4.65.0)\n",
      "Requirement already satisfied: regex in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from pytorch_pretrained_bert) (2022.7.9)\n",
      "Requirement already satisfied: typing_extensions in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.4.0)\n",
      "Collecting botocore<1.32.0,>=1.31.70 (from boto3->pytorch_pretrained_bert)\n",
      "  Downloading botocore-1.31.70-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
      "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->pytorch_pretrained_bert)\n",
      "  Downloading s3transfer-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from botocore<1.32.0,>=1.31.70->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/yuvisa/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.70->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "Downloading boto3-1.28.70-py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.31.70-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, s3transfer, boto3, pytorch_pretrained_bert\n",
      "Successfully installed boto3-1.28.70 botocore-1.31.70 pytorch_pretrained_bert-0.6.2 s3transfer-0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 298834.97B/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "!pip install pytorch_pretrained_bert\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113088ea-840f-42b3-9a6f-1142d68dd767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] This is the sample sentence for BERT word embeddings [SEP]\n"
     ]
    }
   ],
   "source": [
    "text = \"This is the sample sentence for BERT word embeddings\"\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "print (marked_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba93bccf-a4ba-415c-869a-ef212cf8503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'this', 'is', 'the', 'sample', 'sentence', 'for', 'bert', 'word', 'em', '##bed', '##ding', '##s', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0667af51-b345-4b46-ae7d-5166394152a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 101)\n",
      "('this', 2023)\n",
      "('is', 2003)\n",
      "('the', 1996)\n",
      "('sample', 7099)\n",
      "('sentence', 6251)\n",
      "('for', 2005)\n",
      "('bert', 14324)\n",
      "('word', 2773)\n",
      "('em', 7861)\n",
      "('##bed', 8270)\n",
      "('##ding', 4667)\n",
      "('##s', 2015)\n",
      "('[SEP]', 102)\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae30e2-a306-45b1-9858-d0794e18e457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
